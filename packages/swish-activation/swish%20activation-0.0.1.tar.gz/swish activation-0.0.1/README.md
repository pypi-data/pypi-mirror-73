This is swish function that is used in place of Relu because of its non monotonous behaviour and capturing the weights and inputs properly. Although there are ways to convert the normal Relu function to Swish but this package helps importing the swish activation function directly and use it as an activation function.



