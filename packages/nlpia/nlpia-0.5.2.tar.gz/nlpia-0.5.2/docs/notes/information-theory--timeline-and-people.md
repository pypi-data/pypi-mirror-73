# Information Theory

## Timeline

1872, Ludwig Boltzmann, H-theorem with entropy formula
1878, J. Willard Gibbs, Gibbs entropy (probabilistic)
1923, George Santayana, Skepticism and Animal
1924, Harry Nyquist, quantifies "intelligence" and the speed of communicating it
1927, John von Neumann, quantum mechanics Entropy.
1928, Ralph Hartley, Hartley information (log of possible messages)
1929, Leó Szilárd, engine to xform info into energy solved Maxwell's Deamon problem 
1940, Alan Turing, cracked Enigma machine cypher 
1944, Claude Shannon's, theory of information and channel capacity
1947, Richard W. Hamming, Hamming codes for error detection and correction
1951, Solomon Kullback and Richard Leibler, Kullback–Leibler divergence
1951, David A. Huffman, Huffman encoding which uses the optimal lossless compression
1967, Andrew Viterbi, Viterbi algorithm decodes convolutional codes
1989, Phil Katz, .zip format (DEFLATE = LZ77 + Huffman coding)
1995, Benjamin Schumacher, proved quantum noiseless coding theorem coining "qubit"
1999, Melanie Mitchell, genetic algorithms solve Wolfram's automata majority probem
2003, George Susskind, Holographic Principle
1942, Stephen Hawking, Hawking radiation solved information paradox
1957, Noam Chomsky, theory of universal grammar innate in all language users
2000, Hinton, revives deep learning and neural nets