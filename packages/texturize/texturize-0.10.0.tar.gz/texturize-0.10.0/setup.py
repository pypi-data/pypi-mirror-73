# -*- coding: utf-8 -*-
from setuptools import setup

package_dir = \
{'': 'src'}

packages = \
['texturize']

package_data = \
{'': ['*']}

install_requires = \
['creativeai>=0.1.1,<0.2.0',
 'docopt>=0.6.2,<0.7.0',
 'progressbar2>=3.51.3,<4.0.0',
 'schema>=0.7.2,<0.8.0']

entry_points = \
{'console_scripts': ['texturize = texturize.__main__:main']}

setup_kwargs = {
    'name': 'texturize',
    'version': '0.10.0',
    'description': '🤖🖌️ Automatically generate new textures similar to a source photograph.',
    'long_description': 'texturize\n=========\n\n.. image:: docs/gravel-x4.webp\n\nA command-line tool and Python library to automatically generate new textures similar\nto a source image or photograph.  It\'s useful in the context of computer graphics if\nyou want to make variations on a theme or expand the size of an existing texture.\n\nThis software is powered by deep learning technology — using a combination of\nconvolution networks and example-based optimization to synthesize images.  We\'re\nbuilding ``texturize`` as the highest-quality open source library available!\n\n1. `Examples & Demos <#1-examples--demos>`_\n2. `Commands <#2-commands>`_\n3. `Options & Usage <#3-options--usage>`_\n4. `Installation <#4-installation>`_\n\n|Python Version| |License Type| |Project Stars| |Build Status|\n\n----\n\n1. Examples & Demos\n===================\n\nThe examples are available as notebooks, and you can run them directly in-browser\nthanks to Jupyter and Google Colab:\n\n* **Gravel** — `online demo <https://colab.research.google.com/github/photogeniq/neural-texturize/blob/master/examples/Demo_Gravel.ipynb>`__ and `source notebook <https://github.com/photogeniq/neural-texturize/blob/master/examples/Demo_Gravel.ipynb>`__.\n* **Grass** — `online demo <https://colab.research.google.com/github/photogeniq/neural-texturize/blob/master/examples/Demo_Grass.ipynb>`__ and `source notebook <https://github.com/photogeniq/neural-texturize/blob/master/examples/Demo_Grass.ipynb>`__.\n\nThese demo materials are released under the Creative Commons `BY-NC-SA license <https://creativecommons.org/licenses/by-nc-sa/3.0/>`_, including the text, images and code.\n\n.. image:: docs/grass-x4.webp\n\n2. Commands\n===========\n\na) REMIX\n--------\n\n    Generate a variation of any shape from a single texture.\n\nRemix Command-Line\n~~~~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n    Usage:\n        texturize remix SOURCE...\n\n    Examples:\n        texturize remix samples/grass.webp --size=720x360\n        texturize remix samples/gravel.png --size=512x512\n\nRemix Library API\n~~~~~~~~~~~~~~~~~\n\n.. code-block:: python\n\n    from texturize import api, commands, io\n\n    # The input could be any PIL Image in RGB mode.\n    image = io.load_image_from_file("input.png")\n\n    # Coarse-to-fine synthesis runs one octave at a time.\n    remix = commands.Remix(image)\n    for result in api.process_octaves(remix, octaves=5):\n        pass\n\n    # The output can be saved in any PIL-supported format.\n    result.image.save("output.png")\n\n\nRemix Examples\n~~~~~~~~~~~~~~\n\n.. image:: docs/remix-gravel.webp\n\n.. Remix Online Tool\n.. ~~~~~~~~~~~~~~~~~\n.. * `colab notebook <https://colab.research.google.com/github/photogeniq/neural-texturize/blob/master/examples/Tool_Remix.ipynb>`__\n\n----\n\nb) REMAKE\n---------\n\n    Reproduce an original texture in the style of another.\n\n\nRemake Command-Line\n~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n    Usage:\n        texturize remake TARGET [like] SOURCE\n\n    Examples:\n        texturize remake samples/grass1.webp like samples/grass2.webp\n        texturize remake samples/gravel1.png like samples/gravel2.png\n\n\nRemake Library API\n~~~~~~~~~~~~~~~~~~\n\n.. code-block:: python\n\n    from texturize import api, commands\n\n    # The input could be any PIL Image in RGB mode.\n    target = io.load_image_from_file("input1.png")\n    source = io.load_image_from_file("input2.png")\n\n    # Only process one octave to retain photo-realistic output.\n    remake = commands.Remake(target, source)\n    for result in api.process_octaves(remake, octaves=1):\n        pass\n\n    # The output can be saved in any PIL-supported format.\n    result.image.save("output.png")\n\n\nRemake Examples\n~~~~~~~~~~~~~~~\n\n.. image:: docs/remake-grass.webp\n\n.. Remake Online Tool\n.. ~~~~~~~~~~~~~~~~~~\n.. * `colab notebook <https://colab.research.google.com/github/photogeniq/neural-texturize/blob/master/examples/Tool_Remake.ipynb>`__\n\n----\n\nc) MASHUP\n---------\n\n    Combine multiple textures together into one output.\n\n\nMashup Command-Line\n~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n    Usage:\n        texturize mashup SOURCE...\n\n    Examples:\n        texturize mashup samples/grass1.webp samples/grass2.webp\n        texturize mashup samples/gravel1.png samples/gravel2.png\n\n\nMashup Library API\n~~~~~~~~~~~~~~~~~~\n\n.. code-block:: python\n\n    from texturize import api, commands\n\n    # The input could be any PIL Image in RGB mode.\n    sources = [\n        io.load_image_from_file("input1.png"),\n        io.load_image_from_file("input2.png"),\n    ]\n\n    # Only process one octave to retain photo-realistic output.\n    mashup = commands.Mashup(sources)\n    for result in api.process_octaves(mashup, octaves=5):\n        pass\n\n    # The output can be saved in any PIL-supported format.\n    result.image.save("output.png")\n\n\nMashup Examples\n~~~~~~~~~~~~~~~\n\n.. image:: docs/mashup-gravel.webp\n\n.. Mashup Online Tool\n.. ~~~~~~~~~~~~~~~~~~\n.. * `colab notebook <https://colab.research.google.com/github/photogeniq/neural-texturize/blob/master/examples/Tool_Mashup.ipynb>`__\n\n----\n\nd) ENHANCE\n----------\n\n    Increase the resolution or quality of a texture using another as an example.\n\n\nEnhance Command-Line\n~~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n    Usage:\n        texturize enhance TARGET [with] SOURCE\n\n    Examples:\n        texturize enhance samples/grass1.webp with samples/grass2.webp\n        texturize enhance samples/gravel1.png with samples/gravel2.png\n\n\nEnhance Library API\n~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: python\n\n    from texturize import api, commands\n\n    # The input could be any PIL Image in RGB mode.\n    target = io.load_image_from_file("input1.png")\n    source = io.load_image_from_file("input2.png")\n\n    # Only process one octave to retain photo-realistic output.\n    enhance = commands.Enhance(target, source, zoom=2)\n    for result in api.process_octaves(enhance, octaves=2):\n        pass\n\n    # The output can be saved in any PIL-supported format.\n    result.image.save("output.png")\n\n\nEnhance Examples\n~~~~~~~~~~~~~~~~\n\n.. image:: docs/enhance-grass.webp\n\n.. Enhance Online Tool\n.. ~~~~~~~~~~~~~~~~~~~\n.. * `colab notebook <https://colab.research.google.com/github/photogeniq/neural-texturize/blob/master/examples/Tool_Enhance.ipynb>`__\n\n----\n\n\n3. Options & Usage\n==================\n\nFor details about the command-line usage of the tool, see the tool itself:\n\n.. code-block:: bash\n\n    texturize --help\n\nHere are the command-line options currently available, which apply to most of the\ncommands above::\n\n    Options:\n        SOURCE                  Path to source image to use as texture.\n        -s WxH, --size=WxH      Output resolution as WIDTHxHEIGHT. [default: 640x480]\n        -o FILE, --output=FILE  Filename for saving the result, includes format variables.\n                                [default: {command}_{source}{variation}.png]\n\n        --weights=WEIGHTS       Comma-separated list of blend weights. [default: 1.0]\n        --zoom=ZOOM             Integer zoom factor for enhancing. [default: 2]\n\n        --variations=V          Number of images to generate at same time. [default: 1]\n        --seed=SEED             Configure the random number generation.\n        --mode=MODE             Either "patch" or "gram" to manually specify critics.\n        --octaves=O             Number of octaves to process. [default: 5]\n        --threshold=T           Quality for optimization, lower is better.  Defaults to 1e-3\n                                for "patch" and 1e-7 for "gram".\n        --iterations=I          Maximum number of iterations each octave. [default: 99]\n        --device=DEVICE         Hardware to use, either "cpu" or "cuda".\n        --precision=PRECISION   Floating-point format to use, "float16" or "float32".\n        --quiet                 Suppress any messages going to stdout.\n        --verbose               Display more information on stdout.\n        -h, --help              Show this message.\n\n\n4. Installation\n===============\n\nExisting Python [fastest]\n-------------------------\n\nWe recommend using a `Miniconda <https://docs.conda.io/en/latest/miniconda.html>`__ to\nmanage your Python environments.  If you have Python 3.6+ already running, you first\nneed to ensure that PyTorch is available as per the `official installation guide <https://pytorch.org/get-started/locally/>`__:\n\n.. code-block:: bash\n\n    # a) Use this if you have an *Nvidia GPU only*.\n    #   - with `conda`\n    conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n    #   - with `pip`\n    pip install torch==1.5.1+cu102 torchvision==0.6.1+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n\n    # b) Fallback if you just want to run on CPU.\n    #   - with `conda`\n    conda install pytorch torchvision cpuonly -c pytorch\n    #   - with `pip`\n    pip install torch==1.5.1+cpu torchvision==0.6.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n\n\n**NOTE**: Any version of CUDA is suitable as long as PyTorch is working.  Replace the\nstring ``10.2`` or ``102`` in the script above with the version of CUDA driver you have\ninstalled on your machine.\n\nThen, you can fetch the latest version of the library from the Python Package Index\n(PyPI) using the following command:\n\n.. code-block:: bash\n\n    pip install texturize\n\nFinally, you can check if everything worked by calling the command-line script:\n\n.. code-block:: bash\n\n    texturize --help\n\nUse ``pip uninstall`` to remove these packages once you are done.\n\n\nConda Environment [reliable]\n----------------------------\n\nIf you\'re a developer and want to install the library locally, start by cloning the\nrepository to your local disk:\n\n.. code-block:: bash\n\n    git clone https://github.com/photogeniq/neural-texturize.git\n\nThen, you can create a new virtual environment called ``myenv`` by installing\n`Miniconda <https://docs.conda.io/en/latest/miniconda.html>`__ and calling the following\ncommands, depending whether you want to run on CPU or GPU (via CUDA):\n\n.. code-block:: bash\n\n    cd neural-texturize\n\n    # a) Use this if you have an *Nvidia GPU only*.\n    conda env create -n myenv -f tasks/setup-cuda.yml\n\n    # b) Fallback if you just want to run on CPU.\n    conda env create -n myenv -f tasks/setup-cpu.yml\n\nOnce the virtual environment is created, you can activate it and finish the setup of\n``neural-texturize`` with these commands:\n\n.. code-block:: bash\n\n    conda activate myenv\n    poetry install\n\nFinally, you can check if everything worked by calling the script:\n\n.. code-block:: bash\n\n    texturize --help\n\nYou can use ``conda env remove -n myenv`` to delete the virtual environment once you\nare done.\n\n----\n\n|Python Version| |License Type| |Project Stars| |Build Status|\n\n.. |Python Version| image:: https://img.shields.io/pypi/pyversions/texturize\n    :target: https://www.python.org/\n\n.. |License Type| image:: https://img.shields.io/badge/license-AGPL-blue.svg\n    :target: https://github.com/photogeniq/neural-texturize/blob/master/LICENSE\n\n.. |Project Stars| image:: https://img.shields.io/github/stars/photogeniq/neural-texturize.svg?style=flat\n    :target: https://github.com/photogeniq/neural-texturize/stargazers\n\n.. |Project Status| image:: https://img.shields.io/pypi/status/texturize\n    :alt: PyPI - Status\n\n.. |Build Status| image:: https://img.shields.io/github/workflow/status/photogeniq/neural-texturize/build\n    :alt: GitHub Workflow Status\n',
    'author': 'Alex J. Champandard',
    'author_email': '445208+alexjc@users.noreply.github.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/photogeniq/neural-texturize',
    'package_dir': package_dir,
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.6,<4.0',
}


setup(**setup_kwargs)
