{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df-and-order how-to!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is df-and-order anyway?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `df-and-order` your interactions with dataframes become very clean and predictable.\n",
    "\n",
    "Say you've been working on some project for one month already and you had a bunch of experiments. \n",
    "\n",
    "Your working directory ended up like this:\n",
    "\n",
    "    data/\n",
    "    ├── raw_df_proj1.csv\n",
    "    ├── raw_df_new_prj1.csv\n",
    "    ├── cleaned_df_v1.csv\n",
    "    ├── cleaned_df_the_best.csv\n",
    "    ├── cleaned_df.csv\n",
    "    └── cleaned_df_improved.csv\n",
    "Looks familiar? :) Except the namings it would be challenging to find how exactly those files were generated. How to reproduce the result? It'd be feasible to find the roots ( at least if you use some VCS ) yet very time-consuming.\n",
    "\n",
    "`df-and-order` was made to tackle these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In every task it always starts with some intial, commonly raw dataframe. It could be some logs, backend table etc. Then we come to play with it, transform it somehow to finally get a nice&clean dataframe. \n",
    "\n",
    "`df-and-order` assigns a config file to every raw dataframe. The config will contain all the useful metadata and more importantly: declaration of every transformation performed on the dataframe. Just by looking at the config file we would be able to say how some transformation was done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df-and-order` assumes that you already have a dataframe to work with. ( unfortunately it can't provide it for you... )\n",
    "\n",
    "The only thing the lib wants you to do is to organize your dataframes in separate folders. The lib is config-based so it's nice to have a folder that contains all at once:\n",
    "\n",
    "- the initial dataframe \n",
    "\n",
    "- a config for it \n",
    "\n",
    "- all transformed variations of the initial dataframe.\n",
    "\n",
    "You should pick a unique identifier for each dataframe, it will serve as the folder name and the filename for the initial dataframe.\n",
    "\n",
    "Example of such structure:\n",
    "\n",
    "    data/\n",
    "    ├── unique_df_id_1/ - folder with all artifacts for a df with id unique_df_id_1\n",
    "    │   ├── unique_df_id_1.csv - initial dataframe\n",
    "    │   ├── df_config.yaml - contains metadata and declared transformations\n",
    "    │   ├── transform_1_unique_df_id_1.csv - first transformed df\n",
    "    │   └── transform_2_unique_df_id_1.csv - second transformed df\n",
    "    ├── unique_df_id_2/ - same goes with other dataframes\n",
    "    │   ├── ...\n",
    "    │   └── ...\n",
    "    └── unique_df_id_3/\n",
    "        ├── ...\n",
    "        ├── ...\n",
    "        ├── ...\n",
    "        └── ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. We need a dataframe!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create it by hand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.DataFrame({\n",
    "    'num_col': [1,2,3,4,5],\n",
    "    'str_col': ['one', 'two', 'three', 'four', 'five'],\n",
    "    'date_col': ['2020-05-17', '2020-05-18', '2020-05-19', '2020-05-20', '2020-05-21'],\n",
    "    'redundant_col': [0, 0, 0, 0, 0]\n",
    "})\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What an amazing dataframe we have! Let's choose an id for our dataframe. It can be anything, but unique in your data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df_id = 'super_demo_df_2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a folder for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df_folder_path = os.path.join('data', example_df_id)\n",
    "if not os.path.exists(df_folder_path):\n",
    "    os.makedirs(df_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing left is to save our dataframe there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = example_df_id + '.csv'\n",
    "example_df.to_csv(os.path.join(df_folder_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  138 Jul  9 20:40 super_demo_df_2020.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/$example_df_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! Next step is to create a config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config file contains all metadata we find useful and all transformations needed as well.\n",
    "\n",
    "`DfReader` operates in your data folder and knows where to locate all dataframes and configs for them. We will create new config using `DfReader` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# in case you've cloned the repo without installing the lib via pip\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from df_and_order.df_reader import DfReader\n",
    "from df_and_order.df_cache import DfCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DfReader is able to work with any format you want by using `DfCache` subclasses. Each subclass provides logic how to save/load a dataframe. \n",
    "\n",
    "See the example below, where we create simple pandas wrapper for saving/loading csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvDfCache(DfCache):\n",
    "    # just a basic wrapper around pandas csv built-in methods.\n",
    "    def _save(self, df: pd.DataFrame, path: str, *args, **kwargs):\n",
    "        df.to_csv(path, index=False, *args, **kwargs)\n",
    "\n",
    "    def _load(self, path: str, *args, **kwargs) -> pd.DataFrame:\n",
    "        return pd.read_csv(path, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as I mentioned earlier, we first need an instance of `DfReader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we must declare which format our dataframes saved in\n",
    "df_format = 'csv'\n",
    "# can be any path you want, in our case it's 'data' folder\n",
    "dir_path = 'data/'\n",
    "reader = DfReader(dir_path=dir_path, format_to_cache_map={\n",
    "    # DfReader now knows how to work with csv files.\n",
    "    df_format: CsvDfCache()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are all set for now and ready to create a config!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may want to provide any additional information for describing a dataset\n",
    "# here, as an example, we save the info about the dataset's author\n",
    "metadata = {'author': 'Data Man'}\n",
    "# the unique id we came up with above. \n",
    "df_id = example_df_id\n",
    "# other information is already available for us\n",
    "reader.create_df_config(df_id=df_id, # config will store dataframe id as well\n",
    "                        initial_df_format=df_format, # in which format initial dataframe is saved\n",
    "                        metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! let's take a look at the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_id: super_demo_df_2020\r\n",
      "initial_df_format: csv\r\n",
      "metadata:\r\n",
      "  author: Data Man\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/$example_df_id/df_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple as that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.read(df_id=df_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started the section with the code right away because it's so simple and intuitive, no need for comments! :)\n",
    "\n",
    "You just tell `DfReader` a dataframe id and you get the dataframe right back. No more hardcoded paths and mixed up formats. Once you set up `DfReader` - everything just works. \n",
    "\n",
    "Close your eyes and imagine how beneficial it is when working in the same repository with many fellow colleagues. No more shared notebooks with hardcoded paths leading to who-knows-how generated dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still not convinced df-and-order is useful? Just watch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to hide all the logic behind your own subclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazingDfReader(DfReader):\n",
    "    def __init__(self):\n",
    "        # while working in some repo, our data is usually stored in some specific\n",
    "        # place we can provide a path for. Ideally you should write some path generator\n",
    "        # to be able to run the code from any place in your repository.\n",
    "        dir_path = 'data'\n",
    "        reader = super().__init__(dir_path=dir_path, format_to_cache_map={\n",
    "            # here we list all the formats we want to work with\n",
    "            'csv': CsvDfCache()\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enjoy the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader = AmazingDfReader()\n",
    "amazing_reader.read(df_id=df_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you see how cool it is? Anybody can use AmazingDfReader across the codebase in a super clean way without bothering how it's configured!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often our initial dataframe is the raw one and needs to be transformed in some way. \n",
    "\n",
    "e.g. we want still need the initial dataframe since it contains some important information, nonetheless we can't use it to fit our model. No doubt, it requires some changes.\n",
    "\n",
    "`df-and-order` supports `in-memory` transformations as well as `permanent` ones. The only difference is that in the permanent case we store the resulting dataframe on disk next to the initial df. \n",
    "\n",
    "You can see a transformation as a combination of one or many steps.\n",
    "\n",
    "e.g. we may want to:\n",
    "\n",
    "    - first drop column 'redundant_col'\n",
    "    - then convert column 'date_col' from str to date\n",
    "    Do it all in memory only\n",
    "\n",
    "Behind the scenes each step represents a class with the only one method called `transform`. It takes a df and returns a df. Here's the intuitive example:\n",
    "\n",
    "    class DropColsTransformStep(DfTransformStep):\n",
    "        \"\"\"\n",
    "        Simply drops some undesired columns from a dataframe.\n",
    "        \"\"\"\n",
    "        def __init__(self, cols: List[str]):\n",
    "            self._cols_to_drop = cols\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return df.drop(self._cols_to_drop, axis=1)\n",
    "\n",
    "Then we wrap it in the `DfTransformStepConfig` class that doesn't perform the transformation but rather just describes the step:\n",
    "\n",
    "The easiest way to initialize `DfTransformStepConfig` is by passing `DfTransformStep` subclass type along with the init parameters:\n",
    "\n",
    "    DfTransformStepConfig.from_step_type(step_type=DropColsTransformStep,\n",
    "                                         params={'cols': ['redundant_col']}),\n",
    "                                         \n",
    "Important note here:\n",
    "\n",
    "`DfTransformStep` suclass should be stored in the separate python file, not in some notebook etc. \n",
    "\n",
    "Otherwise, `df-and-order` will not be able to locate it.\n",
    "                                         \n",
    "Another way is to provide the full module path for your `DfTransformStep` suclass, including the class name. Choose whatever suits you.\n",
    "\n",
    "    DfTransformStepConfig(module_path='df_and_order.steps.DropColsTransformStep',\n",
    "                          params={'cols': ['redundant_col']}),\n",
    "\n",
    "In both cases `params` will be passed to init method of the specified `DfTransformStep` suclass.\n",
    "\n",
    "All the transforms declarations will be translated to the config file. \n",
    "\n",
    "If it feels overwhelming, just follow the following example and everything will become clear:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to remove `redundant_col` since it doesn't provide any useful information and we also need to convert `date_col` to datetime. Since our dataframe is quite small, we will do all the transformations in memory, without any intermediates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_and_order.df_transform import DfTransformConfig\n",
    "from df_and_order.df_transform_step import DfTransformStepConfig\n",
    "from df_and_order.steps.pd import DropColsTransformStep, DatesTransformStep\n",
    "\n",
    "# we describe all the steps required\n",
    "in_memory_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DropColsTransformStep,\n",
    "                                         params={'cols': ['redundant_col']}),\n",
    "    DfTransformStepConfig.from_step_type(step_type=DatesTransformStep,\n",
    "                                         params={'cols': ['date_col']})\n",
    "]\n",
    "\n",
    "# arbitrary unique id for our transformation\n",
    "example_transform_id = 'model_input'\n",
    "# here's the instance of our entire transform\n",
    "example_transform = DfTransformConfig(transform_id=example_transform_id, \n",
    "                                      df_format=df_format,\n",
    "                                      in_memory_steps=in_memory_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col   date_col\n",
       "0        1     one 2020-05-17\n",
       "1        2     two 2020-05-18\n",
       "2        3   three 2020-05-19\n",
       "3        4    four 2020-05-20\n",
       "4        5    five 2020-05-21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df = amazing_reader.read(df_id=df_id, \n",
    "                                     transform=example_transform)\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   num_col   5 non-null      int64         \n",
      " 1   str_col   5 non-null      object        \n",
      " 2   date_col  5 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 248.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "transformed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretty rad, isn't it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our transform is now visible in the config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_id: super_demo_df_2020\r\n",
      "initial_df_format: csv\r\n",
      "metadata:\r\n",
      "  author: Data Man\r\n",
      "transforms:\r\n",
      "  model_input:\r\n",
      "    df_format: csv\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.pd.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n",
      "    - module_path: df_and_order.steps.pd.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/$example_df_id/df_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: you are free to edit the config file manually as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a transform is declared in the config file you can just pass `transform_id` to the `DfReader.read` method. See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col   date_col\n",
       "0        1     one 2020-05-17\n",
       "1        2     two 2020-05-18\n",
       "2        3   three 2020-05-19\n",
       "3        4    four 2020-05-20\n",
       "4        5    five 2020-05-21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, transform_id=example_transform_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you want to switch to your initial dataframe? No problem! Just don't pass `transform_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df = amazing_reader.read(df_id=df_id)\n",
    "initial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   num_col        5 non-null      int64 \n",
      " 1   str_col        5 non-null      object\n",
      " 2   date_col       5 non-null      object\n",
      " 3   redundant_col  5 non-null      int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 288.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "initial_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's cover the case when we want to persist a transform's result. It's a good idea to remove `redundant_col` once and for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we describe all the steps required\n",
    "in_memory_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DatesTransformStep,\n",
    "                                         params={'cols': ['date_col']})\n",
    "]\n",
    "\n",
    "# let's just move DropColsTransformStep from in_memory to permanent steps\n",
    "permanent_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DropColsTransformStep,\n",
    "                                     params={'cols': ['redundant_col']}),\n",
    "]\n",
    "\n",
    "# arbitrary unique id for our transformation\n",
    "permanent_transform_id = 'model_input_permanent'\n",
    "# here's the instance of our entire transform\n",
    "permanent_transform = DfTransformConfig(transform_id=permanent_transform_id, \n",
    "                                        df_format=df_format,\n",
    "                                        in_memory_steps=in_memory_steps,\n",
    "                                        permanent_steps=permanent_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col   date_col\n",
       "0        1     one 2020-05-17\n",
       "1        2     two 2020-05-18\n",
       "2        3   three 2020-05-19\n",
       "3        4    four 2020-05-20\n",
       "4        5    five 2020-05-21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = amazing_reader.read(df_id=df_id, \n",
    "                               transform=permanent_transform)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_id: super_demo_df_2020\r\n",
      "initial_df_format: csv\r\n",
      "metadata:\r\n",
      "  author: Data Man\r\n",
      "transforms:\r\n",
      "  model_input:\r\n",
      "    df_format: csv\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.pd.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n",
      "    - module_path: df_and_order.steps.pd.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n",
      "  model_input_permanent:\r\n",
      "    df_format: csv\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.pd.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n",
      "    permanent:\r\n",
      "    - module_path: df_and_order.steps.pd.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/$example_df_id/df_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  657 Jul  9 20:41 df_config.yaml\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  114 Jul  9 20:41 model_input_permanent_super_demo_df_2020.csv\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  138 Jul  9 20:40 super_demo_df_2020.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/$example_df_id/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we now have `model_input_permanent_super_demo_df_2020.csv` file stored to the disk.\n",
    "\n",
    "Every time after calling `read` with the transform_id - it recovers from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col   date_col\n",
       "0        1     one 2020-05-17\n",
       "1        2     two 2020-05-18\n",
       "2        3   three 2020-05-19\n",
       "3        4    four 2020-05-20\n",
       "4        5    five 2020-05-21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, \n",
    "                    transform=permanent_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important note: `in-memory` transforms run everytime when your read a dataframe, no matter it was stored on the disk or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it, now you are ready to try df-and-order power in your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some advanced stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reacting to changes in transformations codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, even after having all the transformation steps declared in the config file, it doesn't prevent us from code changes in those steps subclasses. Once a step is changed, we have an outdated transformed dataframe on the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df-and-order` has a built-in safety mechanism for avoiding such cases.\n",
    "\n",
    "It compares the creation date of the persisted dataframe with the last modification date of any of the permanent steps. Meaning if a permanent step we used to transform the dataframe was changed afterwards - we can no longer use it. It's crucial while working in the same repo with others. All your team members must read the same dataframe using the same config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_steps.steps import DummyTransformStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from df_and_order.df_transform_step import DfTransformStep\r\n",
      "\r\n",
      "class DummyTransformStep(DfTransformStep):\r\n",
      "    def transform(self, df):\r\n",
      "        return df\r\n"
     ]
    }
   ],
   "source": [
    "!cat example_steps/steps.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform above does literally nothing, but bear with me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "permanent_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DummyTransformStep, params={})\n",
    "]\n",
    "dummy_transform_id = 'dummy'\n",
    "dummy_transform = DfTransformConfig(transform_id=dummy_transform_id, \n",
    "                                    df_format=df_format,\n",
    "                                    permanent_steps=permanent_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, \n",
    "                    transform=dummy_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_id: super_demo_df_2020\r\n",
      "initial_df_format: csv\r\n",
      "metadata:\r\n",
      "  author: Data Man\r\n",
      "transforms:\r\n",
      "  dummy:\r\n",
      "    df_format: csv\r\n",
      "    permanent:\r\n",
      "    - module_path: example_steps.steps.DummyTransformStep\r\n",
      "  model_input:\r\n",
      "    df_format: csv\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.pd.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n",
      "    - module_path: df_and_order.steps.pd.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n",
      "  model_input_permanent:\r\n",
      "    df_format: csv\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.pd.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n",
      "    permanent:\r\n",
      "    - module_path: df_and_order.steps.pd.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/super_demo_df_2020/df_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  758 Jul  9 20:41 df_config.yaml\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  138 Jul  9 20:41 dummy_super_demo_df_2020.csv\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  114 Jul  9 20:41 model_input_permanent_super_demo_df_2020.csv\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  138 Jul  9 20:40 super_demo_df_2020.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/super_demo_df_2020/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing new so far. But now let's change the transform step file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('example_steps/steps.py', \"a\") as file:\n",
    "    file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we then try to read the transformed dataframe - it crashes since the code of our dummy step was modified after the dataframe was persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "['example_steps.steps.DummyTransformStep'] steps of dummy transform were changed since the df was generated, delete the file and try again to regenerate the df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-120d5f230a47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mamazing_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy_transform_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, df_id, transform_id, transform, forced)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_transformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_initial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36m_read_transformed\u001b[0;34m(self, df_id, transform, df_config, forced)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransformed_df_exists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             return self._try_to_read_cached_transform(\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             )\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36m_try_to_read_cached_transform\u001b[0;34m(self, df_id, df_config, forced, transform)\u001b[0m\n\u001b[1;32m    183\u001b[0m             )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_check_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_cached_transformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36m_try_check_transform\u001b[0;34m(self, df_id, transform, forced, child_transform)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_check_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchild_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     def _check_transform(\n",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36m_check_transform\u001b[0;34m(self, df_id, transform, forced, child_transform)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mPerforms\u001b[0m \u001b[0mvarious\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \"\"\"\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# which transform are we checking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36m_check_ts\u001b[0;34m(self, df_id, forced, transform)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Warning: {base_warning}, reading it anyway because the operation was forced\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{base_warning}, \"\u001b[0m \u001b[0;34m\"delete the file and try again to regenerate the df.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: ['example_steps.steps.DummyTransformStep'] steps of dummy transform were changed since the df was generated, delete the file and try again to regenerate the df."
     ]
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, transform_id=dummy_transform_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to deal with it. \n",
    "\n",
    "First one is to force the read operation by passing `forced=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: ['example_steps.steps.DummyTransformStep'] steps of dummy transform were changed since the df was generated, reading it anyway because the operation was forced\n",
      "Warning: ['example_steps.steps.DummyTransformStep'] steps of dummy transform were changed since the df was generated, reading it anyway because the operation was forced\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, transform_id=dummy_transform_id, forced=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can save you time when you are sure that your data will be consistent with your expectations yet this way is certainly not recommended.\n",
    "\n",
    "Yeah, it can be annoying to get such an error after some minor changes, e.g. something was renamed or blank lines were removed.\n",
    "\n",
    "But it's better to get an error rather than outdated wrong dataframe.\n",
    "If we remove the file and try again - everything works just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/$example_df_id/dummy_super_demo_df_2020.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, transform_id=dummy_transform_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on in-memory transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your transform consists of both in-memory and permanent steps, your in-memory steps are not allowed to change the shape of df. Remember, in-memory steps are applied every time your read a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made up example when we remove some cols in memory and then perform \n",
    "# some permanent transform step that will cause our dataframe to be persisted\n",
    "in_memory_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DropColsTransformStep,\n",
    "                                     params={'cols': ['redundant_col']}),\n",
    "]\n",
    "permanent_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DatesTransformStep,\n",
    "                                         params={'cols': ['date_col']})\n",
    "]\n",
    "\n",
    "# arbitrary unique id for our transformation\n",
    "bad_in_memory_transform_id = 'bad_in_memory'\n",
    "# here's the instance of our entire transform\n",
    "bad_in_memory_transform = DfTransformConfig(transform_id=bad_in_memory_transform_id, \n",
    "                                            df_format='csv',\n",
    "                                            in_memory_steps=in_memory_steps,\n",
    "                                            permanent_steps=permanent_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error: A permanent transform is also present, hence your in-memory transform can't modify the shape of the initial df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b1cc71d998af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mamazing_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbad_in_memory_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, df_id, transform_id, transform, forced)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_transformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_initial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36m_read_transformed\u001b[0;34m(self, df_id, transform, df_config, forced)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_source_df_for_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_df_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/df-and-order/df_and_order/df_reader.py\u001b[0m in \u001b[0;36m_apply_df_transforms\u001b[0;34m(self, df_id, df, df_config, transform)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mboth_transform_types_are_present\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf_shape_has_changed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 raise Exception(\n\u001b[0;32m--> 201\u001b[0;31m                     \u001b[0;34m\"Error: A permanent transform is also present, hence your \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                     \u001b[0;34m\"in-memory transform can't modify the shape of the initial df.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 )\n",
      "\u001b[0;31mException\u001b[0m: Error: A permanent transform is also present, hence your in-memory transform can't modify the shape of the initial df."
     ]
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, transform=bad_in_memory_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
