{
    "emb_size": 768,
    "feedforward_size": 3072,
    "hidden_size": 768,
    "heads_num": 12,
    "layers_num": 12,
    "dropout": 0.1,
    "embedding": "bert",
    "encoder": "bert",
    "pooling": "first",
    "vocab_path": "google_uncased_en_vocab.txt",
    "pretrained_model_path": "google_bert_base_en.bin",
    "pretrained_model_url": "https://not/uploaded/now"
}
